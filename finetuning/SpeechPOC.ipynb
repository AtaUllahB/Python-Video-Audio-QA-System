{"cells":[{"cell_type":"markdown","metadata":{"id":"MEDUDZW53z03"},"source":["# Extract Audio from Video"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jxS5v9Z63z09","outputId":"69fd406c-221f-4e79-ab40-9b35dd79dd22"},"outputs":[{"name":"stdout","output_type":"stream","text":["MoviePy - Writing audio in audioFile1.mp3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                      "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["from moviepy.editor import VideoFileClip\n","\n","video_file_path = 'sample1.mp4'\n","audio_file_path = 'audioFile1.mp3'\n","\n","video = VideoFileClip(video_file_path)\n","video.audio.write_audiofile(audio_file_path)"]},{"cell_type":"markdown","metadata":{"id":"46RSMfzd3z1B"},"source":["# Transcribe Audio with Whisper"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4VjQGlD53z1C","outputId":"bf79b33e-4d43-42d2-a076-4e69f9c9c89b"},"outputs":[{"name":"stdout","output_type":"stream","text":[" The text in video: \n","  Let's assume your monthly income were to somehow double. Congratulations! You can now, for the most part, afford to buy two times more stuff. But what if the monthly income of everyone else were to also double? Well, in that case, you'd no longer be able to buy two times more stuff, because since everyone else also earns two times more, there would be two times more money chasing roughly the same number of goods. Let's take things one step further. What if your income doubles, but the income of everyone else triples? In that case, you'd actually become poorer. Why? Because making two times more money is not enough to keep up with everyone else, who now makes three times more. If there's an overall increase in the price of goods and services of X percent this year, you have to earn at least X percent more than last year to avoid becoming poorer in real terms. So, the salary makes the effects of inflation crystal clear. Today, each dollar buys you approximately 39 times less potatoes than 100 years ago, or 20 times less coffee, 24 times less bread, and so on.\n"]}],"source":["import whisper\n","whisper_model = whisper.load_model(\"base\")\n","result = whisper_model.transcribe(\"audioFile1.mp3\")\n","videoText = result[\"text\"]\n","print(f' The text in video: \\n {result[\"text\"]}')"]},{"cell_type":"markdown","metadata":{"id":"O8pPT8jb3z1D"},"source":["# Q&A with Bert"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"u9zDJMXp3z1D","outputId":"5b093e4a-2ef0-4fda-96ab-a8cb63d80e39"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertForQuestionAnswering, BertTokenizer\n","import torch\n","\n","# Load pre-trained model and tokenizer\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"qCYhOAQ03z1E"},"outputs":[],"source":["# Example text and question\n","question = \"What does it say about inflation?\"\n","\n","# Tokenize input\n","inputs = tokenizer(question, videoText, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"D2ijx9cO3z1F"},"outputs":[],"source":["# Generate predictions\n","outputs = model(**inputs)\n","\n","# Get the start and end scores\n","start_scores = outputs.start_logits\n","end_scores = outputs.end_logits"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"xyDVBubN3z1F","outputId":"b415eb2a-170f-46e9-b6fa-c43819da354a"},"outputs":[{"name":"stdout","output_type":"stream","text":["the salary makes the effects of inflation crystal clear\n"]}],"source":["\n","# Get the most likely start and end scores\n","start_index = torch.argmax(start_scores)\n","end_index = torch.argmax(end_scores) +  1\n","\n","# Convert token indices to actual text\n","answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index]))\n","\n","print(answer)"]},{"cell_type":"markdown","metadata":{},"source":["# Using the SQUAD data set for FineTuning."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading readme: 100%|██████████| 8.92k/8.92k [00:00<00:00, 29.9MB/s]\n","Downloading data: 100%|██████████| 16.4M/16.4M [00:05<00:00, 2.77MB/s]\n","Downloading data: 100%|██████████| 1.35M/1.35M [00:02<00:00, 516kB/s]\n","Generating train split: 100%|██████████| 130319/130319 [00:00<00:00, 1411674.40 examples/s]\n","Generating validation split: 100%|██████████| 11873/11873 [00:00<00:00, 1107850.13 examples/s]"]},{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 11873\n","    })\n","})\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from datasets import load_dataset\n","\n","# Load SQuAD version 2\n","dataset = load_dataset(\"squad_v2\")\n","print(dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Map:  25%|██▌       | 3000/11873 [00:00<00:02, 3593.98 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n","Map: 100%|██████████| 11873/11873 [00:03<00:00, 3302.95 examples/s]\n"]}],"source":["\n","import numpy as np\n","from transformers import AutoTokenizer\n","import numpy as np\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', use_fast=True)\n","\n","def find_answer_positions(context, answer):\n","    # Check if the answer is not empty\n","    if answer[\"text\"]:\n","        start_idx = context.find(answer[\"text\"][0])\n","        end_idx = start_idx + len(answer[\"text\"][0]) - 1\n","\n","        # Tokenize context to find token positions, ensuring not to add special tokens\n","        tokenized_context = tokenizer(context, return_offsets_mapping=True, add_special_tokens=False)\n","        offsets = tokenized_context[\"offset_mapping\"]\n","\n","        start_token_pos = None\n","        end_token_pos = None\n","\n","        for i, offset in enumerate(offsets):\n","            if start_idx >= offset[0] and start_idx <= offset[1]:\n","                start_token_pos = i\n","            if end_idx >= offset[0] and end_idx <= offset[1]:\n","                end_token_pos = i\n","                break  # Stop once the end position is found\n","\n","        return start_token_pos, end_token_pos\n","    else:\n","        # Return default positions if no answer is provided\n","        return 0, 0\n","\n","\n","def preprocess_data(data):\n","    # Tokenize questions and contexts\n","    inputs = tokenizer(data[\"question\"], data[\"context\"], truncation=True, padding=\"max_length\", max_length=384, return_tensors=\"pt\")\n","\n","    # Initialize lists to hold start and end positions\n","    start_positions = []\n","    end_positions = []\n","\n","    for context, answer in zip(data[\"context\"], data[\"answers\"]):\n","        # Use the manual approach to find start and end token positions\n","        start_pos, end_pos = find_answer_positions(context, answer)\n","        \n","        # Append the positions to the lists\n","        start_positions.append(start_pos if start_pos is not None else 0)\n","        end_positions.append(end_pos if end_pos is not None else 0)\n","\n","    # Convert lists to tensors and add them to the inputs\n","    inputs[\"start_positions\"] = torch.tensor(start_positions, dtype=torch.long)\n","    inputs[\"end_positions\"] = torch.tensor(end_positions, dtype=torch.long)\n","\n","    return inputs\n","\n","\n","# Apply the preprocessing function to the training and validation dataset\n","train_dataset = dataset['train'].map(preprocess_data, batched=True)\n","validation_dataset = dataset['validation'].map(preprocess_data, batched=True)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def collate_fn(batch):\n","    # Initialize containers for our batched data\n","    batched_output = {\n","        'input_ids': [],\n","        'attention_mask': [],\n","        'start_positions': [],\n","        'end_positions': []\n","    }\n","    \n","    # Process each item in our batch\n","    for item in batch:\n","        for key in batched_output.keys():\n","            # Ensure every item is a tensor. If it's not, convert it.\n","            element = item[key]\n","            if not isinstance(element, torch.Tensor):\n","                element = torch.tensor(element, dtype=torch.long)\n","            batched_output[key].append(element)\n","    \n","    # Now concatenate each list of tensors along a new batch dimension\n","    for key in batched_output.keys():\n","        batched_output[key] = torch.stack(batched_output[key], dim=0)\n","    \n","    return batched_output\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=16, collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dc9f37115a14139b924147f73f0ea5c","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d135a95f557e4a86baeb0f59935ac250","version_major":2,"version_minor":0},"text/plain":["Batch:   0%|          | 0/8145 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 39\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from transformers import AdamW\n","from tqdm.notebook import tqdm  # Use tqdm.auto if you're running in a non-notebook environment\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","model.train()\n","for epoch in tqdm(range(1), desc=\"Epoch\"):  # Wrapping the epoch loop with tqdm for progress tracking\n","    # Initialize a progress bar for the batches within the current epoch\n","    progress_bar = tqdm(train_dataloader, desc=\"Batch\", leave=False)\n","    for batch in progress_bar:\n","        # Move batch to device\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        \n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        \n","        optimizer.step()\n","        optimizer.zero_grad()\n","        \n","        # Optional: Update the progress bar with the current loss\n","        progress_bar.set_postfix({'loss': loss.item()})\n","    \n","    # Save model and tokenizer checkpoints\n","    model.save_pretrained(f\"./model_checkpoint_epoch_{epoch}\")\n","    tokenizer.save_pretrained(f\"./model_checkpoint_epoch_{epoch}\")\n","\n","print(\"Training completed.\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS]\n"]}],"source":["fine_tuned_model = BertForQuestionAnswering.from_pretrained('./model_checkpoint_epoch_0')\n","fine_tuned_tokenizer = BertTokenizer.from_pretrained('./model_checkpoint_epoch_0')\n","\n","# Example text and question\n","question = \"What does it say about inflation?\"\n","\n","# Tokenize input\n","inputs = tokenizer(question, videoText, return_tensors=\"pt\")\n","\n","# Generate predictions\n","outputs = fine_tuned_model(**inputs)\n","\n","# Get the start and end scores\n","start_scores = outputs.start_logits\n","end_scores = outputs.end_logits\n","# Get the most likely start and end scores\n","start_index = torch.argmax(start_scores)\n","end_index = torch.argmax(end_scores) +  1\n","\n","# Convert token indices to actual text\n","answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index]))\n","\n","print(answer)"]},{"cell_type":"markdown","metadata":{},"source":["# Testing the preprocessing\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","Start position: 66, End position: 69\n","\n","Original context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","Start position: 54, End position: 56\n","\n","Original context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","Start position: 127, End position: 127\n","\n","Original context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","Start position: 46, End position: 48\n","\n","Original context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","Start position: 68, End position: 69\n","\n"]}],"source":["data = dataset['train'][:5]  # Adjust index for sampling\n","preprocessed_samples = preprocess_data(data)\n","for i, sample in enumerate(sample_data['context']):\n","    print(f\"Original context: {sample}\")\n","    print(f\"Start position: {preprocessed_samples['start_positions'][i]}, End position: {preprocessed_samples['end_positions'][i]}\\n\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Expected answer: in the late 1990s\n","Recovered answer: in the late 1990s\n","\n","Expected answer: singing and dancing\n","Recovered answer: singing and dancing\n","\n","Expected answer: 2003\n","Recovered answer: 2003\n","\n","Expected answer: Houston, Texas\n","Recovered answer: houston, texas\n","\n","Expected answer: late 1990s\n","Recovered answer: late 1990s\n","\n"]}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"squad_v2\")\n","\n","# Attempting to create a sample slice of the data\n","data = dataset['train'].select(range(5))  # This should ensure data is a proper subset of the dataset\n","\n","for i in range(len(data)):\n","    example = data[i]  # Access each example by index\n","    context = example['context']\n","    answer_texts = example['answers']['text']\n","    answer = answer_texts[0] if answer_texts else 'No answer found'\n","    \n","    # Assuming your find_answer_positions and the rest of the code is correct\n","    start_pos, end_pos = find_answer_positions(context, {'text': [answer]})\n","    tokenized_context = tokenizer(context, return_offsets_mapping=True, add_special_tokens=False)\n","    answer_tokens = tokenized_context['input_ids'][start_pos:end_pos+1] if start_pos is not None and end_pos is not None else []\n","    print(f\"Expected answer: {answer}\")\n","    print(f\"Recovered answer: {tokenizer.decode(answer_tokens)}\\n\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training again"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f621c478243d4d08932b201b973bdd10","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e98d4f9ce2844089496657133424cde","version_major":2,"version_minor":0},"text/plain":["Batch:   0%|          | 0/8145 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm.auto import tqdm\n","import torch\n","import numpy as np\n","from datasets import load_metric\n","\n","# Assuming dataset, model, tokenizer, preprocess_data are already defined\n","dataset = load_dataset(\"squad_v2\")\n","\n","# Apply preprocessing\n","train_dataset = dataset['train'].map(preprocess_data, batched=True)\n","validation_dataset = dataset['validation'].map(preprocess_data, batched=True)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=16, collate_fn=collate_fn)\n","\n","# Setup device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Setup optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Setup scheduler\n","total_steps = len(train_dataloader) * 3  # for 3 epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=0,\n","                                            num_training_steps=total_steps)\n","\n","# Setup metric\n","metric = load_metric(\"squad_v2\")\n","\n","# Function to compute metrics\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","# Training\n","model.train()\n","best_validation_score = float('-inf')\n","for epoch in tqdm(range(3), desc=\"Epoch\"):\n","    progress_bar = tqdm(train_dataloader, desc=\"Batch\", leave=False)\n","    for batch in progress_bar:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.set_postfix({'loss': loss.item()})\n","    \n","    # Validation\n","    model.eval()\n","    for batch in tqdm(validation_dataloader, desc=\"Validating\", leave=False):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model(**batch)\n","        \n","        # Assume outputs are logits and you have a way to calculate your validation score\n","        logits = outputs.logits.detach().cpu().numpy()\n","        labels = batch['labels'].detach().cpu().numpy()  # adjust this based on your actual label key\n","        validation_score = compute_metrics((logits, labels))\n","        \n","        # Check if this is the best model based on validation score\n","        if validation_score > best_validation_score:\n","            best_validation_score = validation_score\n","            print(f\"New best score: {validation_score}. Saving model.\")\n","            model.save_pretrained(\"./best_model\")\n","            tokenizer.save_pretrained(\"./best_model\")\n","    \n","    model.train()\n","\n","print(\"Training completed.\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
